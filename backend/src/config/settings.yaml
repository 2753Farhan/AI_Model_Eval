# AI_ModelEval Configuration File

# Paths configuration
paths:
  data_dir: "data"
  results_dir: "results"
  cache_dir: "cache"
  log_dir: "logs"
  repo_url: "https://github.com/openai/human-eval.git"

# Models configuration
models:
  ollama_base_url: "http://localhost:11434"
  hf_api_key: ""  # Add your HuggingFace token if needed
  default_models:
    - "codellama:7b"
    - "codellama:13b"
    - "starcoder:1b"
    - "tinyllama:1.1b"
  
  custom_models:
    - name: "codellama:34b"
      adapter: "ollama"
      config:
        base_url: "http://localhost:11434"
        max_tokens: 1024
        temperature: 0.7
    
    - name: "gpt-3.5-turbo"
      adapter: "openai"
      config:
        api_key: "${OPENAI_API_KEY}"
        max_tokens: 1024
        temperature: 0.7

# Evaluation configuration
evaluation:
  num_samples_per_task: 5
  timeout_seconds: 30
  max_memory_mb: 512
  prompt_strategies:
    - "zero_shot"
    - "few_shot"
    - "chain_of_thought"
  
  resource_limits:
    max_concurrent: 4
    max_cpu_percent: 80
    max_memory_percent: 80

# Metrics configuration
metrics:
  enable_functional: true
  enable_quality: true
  enable_semantic: true
  pass_at_k_values: [1, 5, 10]
  
  weights:
    pass@1: 0.4
    pass@5: 0.3
    codebleu: 0.2
    maintainability: 0.1

# Dashboard configuration
dashboard:
  host: "0.0.0.0"
  port: 5000
  debug: false
  secret_key: "change-this-in-production"
  auto_refresh: true
  refresh_interval: 30

# Logging configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/app.log"
  max_size_mb: 10
  backup_count: 5

# Cache configuration
cache:
  enabled: true
  ttl_seconds: 3600
  max_size_mb: 1024
  backend: "disk"  # disk, redis, memory

# Security configuration
security:
  enable_authentication: false
  session_timeout_hours: 24
  max_login_attempts: 5
  password_min_length: 8
  require_email_verification: false