2026-01-10 14:13:36,612 - INFO - [__main__] - AI Model Evaluation Starting...
2026-01-10 14:13:36,613 - INFO - [__main__] - STARTING: Configuration Initialization
2026-01-10 14:13:36,623 - INFO - [__main__] - Initializing system components...
2026-01-10 14:13:36,633 - INFO - [model_layer.model_integration] - ✅ Ollama client initialized
2026-01-10 14:13:36,648 - WARNING - [evaluation_layer.sandbox_executor] - Docker not available: Error while fetching server API version: (2, 'CreateFile', 'The system cannot find the file specified.'). Using fallback execution.
2026-01-10 14:13:36,649 - INFO - [__main__] - All components initialized successfully
2026-01-10 14:13:36,649 - INFO - [__main__] - COMPLETED: Configuration Initialization in 0.04s
2026-01-10 14:13:36,649 - INFO - [__main__] - Starting evaluation with test configuration...
2026-01-10 14:13:36,649 - INFO - [__main__] - Starting AI Model Evaluation Pipeline with Enhanced Debugging
2026-01-10 14:13:36,650 - INFO - [__main__] - ============================================================
2026-01-10 14:13:36,650 - INFO - [__main__] - Configuration: 1 models, 2 samples per task
2026-01-10 14:13:36,650 - INFO - [__main__] - STARTING: Dataset Loading
2026-01-10 14:13:36,650 - INFO - [__main__] - Loading HumanEval dataset...
2026-01-10 14:13:36,684 - INFO - [__main__] - Loaded 164 problems
2026-01-10 14:13:36,684 - INFO - [__main__] - COMPLETED: Dataset Loading in 0.03s
2026-01-10 14:13:36,684 - INFO - [__main__] - STARTING: Model Detection and Validation
2026-01-10 14:13:36,685 - INFO - [__main__] - Checking model availability...
2026-01-10 14:13:38,960 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:38,967 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:38,967 - INFO - [__main__] - Available models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:38,967 - INFO - [__main__] - Final model selection: ['codellama:7b']
2026-01-10 14:13:38,967 - INFO - [__main__] - COMPLETED: Model Detection and Validation in 2.28s
2026-01-10 14:13:38,968 - INFO - [__main__] - STARTING: Code Generation
2026-01-10 14:13:38,968 - INFO - [__main__] - Generating code solutions...
2026-01-10 14:13:38,976 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:38,976 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:42,204 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:42,205 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:13:42,708 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:42,709 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:43,136 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:43,136 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:13:43,650 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:43,650 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:43,957 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:43,957 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:13:44,463 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:44,463 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:45,397 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:45,398 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:13:45,907 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:45,907 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:46,406 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:46,406 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:13:46,914 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:46,915 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:47,283 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:47,283 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:13:47,791 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:47,792 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:48,140 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:48,141 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:13:48,651 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:48,652 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:48,940 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:48,941 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:13:49,452 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:49,454 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:49,743 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:49,744 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:13:50,252 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:50,253 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:50,588 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:50,589 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:13:51,101 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:51,102 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:51,374 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:51,375 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:13:51,884 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:51,886 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:52,153 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:52,153 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:13:52,664 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:52,666 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:52,946 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:52,946 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:13:53,456 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:53,457 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:53,745 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:53,745 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:13:54,258 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:54,260 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:54,531 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:54,531 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:13:55,035 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:55,035 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:55,306 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:55,306 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:13:55,812 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:55,812 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:56,088 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:56,088 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:13:56,598 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:56,599 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:56,939 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:56,940 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:13:57,444 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:57,445 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:57,784 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:57,784 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:13:58,288 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:58,288 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:13:59,214 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:13:59,215 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:13:59,719 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:13:59,719 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:00,577 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:00,577 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:14:01,087 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:01,089 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:01,367 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:01,368 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:14:01,873 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:01,873 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:02,159 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:02,160 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:14:02,668 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:02,668 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:02,952 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:02,952 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:14:03,456 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:03,458 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:03,790 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:03,790 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:14:04,300 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:04,302 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:04,635 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:04,635 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.8 GiB) (status code: 500)
2026-01-10 14:14:05,149 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:05,150 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:05,517 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:05,518 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.8 GiB) (status code: 500)
2026-01-10 14:14:06,021 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:06,023 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:06,383 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:06,384 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.7 GiB) (status code: 500)
2026-01-10 14:14:06,888 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:06,888 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:07,313 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:07,313 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.7 GiB) (status code: 500)
2026-01-10 14:14:07,823 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:07,825 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:08,127 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:08,129 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.7 GiB) (status code: 500)
2026-01-10 14:14:08,639 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:08,640 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:08,945 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:08,945 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.7 GiB) (status code: 500)
2026-01-10 14:14:09,458 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:09,460 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:09,752 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:09,752 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.8 GiB) (status code: 500)
2026-01-10 14:14:10,260 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:10,261 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:10,553 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:10,553 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.7 GiB) (status code: 500)
2026-01-10 14:14:11,063 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:11,064 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:12,048 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:12,049 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.8 GiB) (status code: 500)
2026-01-10 14:14:12,552 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:12,552 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:13,402 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:13,402 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.8 GiB) (status code: 500)
2026-01-10 14:14:13,905 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:13,906 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:14,739 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:14,739 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.7 GiB) (status code: 500)
2026-01-10 14:14:15,243 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:15,245 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:15,642 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:15,642 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.8 GiB) (status code: 500)
2026-01-10 14:14:16,147 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:16,147 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:16,491 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:16,491 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.7 GiB) (status code: 500)
2026-01-10 14:14:16,997 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:16,997 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:17,297 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:17,297 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.7 GiB) (status code: 500)
2026-01-10 14:14:17,800 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:17,801 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:18,086 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:18,086 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.7 GiB) (status code: 500)
2026-01-10 14:14:18,596 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:18,597 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:19,419 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:19,419 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.7 GiB) (status code: 500)
2026-01-10 14:14:19,927 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:19,928 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:20,333 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:20,335 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.7 GiB) (status code: 500)
2026-01-10 14:14:20,841 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:20,843 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:21,792 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:21,793 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.3 GiB) (status code: 500)
2026-01-10 14:14:22,297 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:22,297 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:23,393 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:23,396 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.6 GiB) (status code: 500)
2026-01-10 14:14:23,901 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:23,901 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:24,859 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:24,860 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.4 GiB) (status code: 500)
2026-01-10 14:14:25,367 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:25,368 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:26,393 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:26,394 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.1 GiB) (status code: 500)
2026-01-10 14:14:26,905 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:26,907 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:27,617 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:27,618 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (967.7 MiB) (status code: 500)
2026-01-10 14:14:28,124 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:28,125 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:29,118 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:29,119 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (783.0 MiB) (status code: 500)
2026-01-10 14:14:29,630 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:29,633 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:30,059 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:30,060 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (676.9 MiB) (status code: 500)
2026-01-10 14:14:30,563 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:30,564 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:31,497 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:31,497 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.3 GiB) (status code: 500)
2026-01-10 14:14:32,001 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:32,002 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:32,361 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:32,361 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.5 GiB) (status code: 500)
2026-01-10 14:14:32,871 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:32,872 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:33,789 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:33,789 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.5 GiB) (status code: 500)
2026-01-10 14:14:34,297 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:34,297 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:35,126 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:35,127 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.6 GiB) (status code: 500)
2026-01-10 14:14:35,632 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:35,633 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:35,909 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:35,910 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.5 GiB) (status code: 500)
2026-01-10 14:14:36,420 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:36,420 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:36,697 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:36,697 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.5 GiB) (status code: 500)
2026-01-10 14:14:37,202 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:37,203 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:37,468 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:37,469 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.6 GiB) (status code: 500)
2026-01-10 14:14:37,979 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:37,980 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:38,906 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:38,906 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.6 GiB) (status code: 500)
2026-01-10 14:14:39,419 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:39,421 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:40,251 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:40,251 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.5 GiB) (status code: 500)
2026-01-10 14:14:40,762 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:40,764 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:41,122 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:41,123 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.5 GiB) (status code: 500)
2026-01-10 14:14:41,634 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:41,636 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:41,908 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:41,908 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.5 GiB) (status code: 500)
2026-01-10 14:14:42,418 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:42,422 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:42,703 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:42,704 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.5 GiB) (status code: 500)
2026-01-10 14:14:43,208 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:43,209 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:43,482 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:43,482 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.5 GiB) (status code: 500)
2026-01-10 14:14:43,992 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:43,994 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:44,342 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:44,343 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.5 GiB) (status code: 500)
2026-01-10 14:14:44,848 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:44,849 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:45,195 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:45,196 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.5 GiB) (status code: 500)
2026-01-10 14:14:45,704 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:45,706 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:46,003 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:46,004 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.5 GiB) (status code: 500)
2026-01-10 14:14:46,513 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:46,515 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:46,852 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:46,853 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.5 GiB) (status code: 500)
2026-01-10 14:14:47,364 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:47,365 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:47,640 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:47,641 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.5 GiB) (status code: 500)
2026-01-10 14:14:48,149 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:48,151 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:48,870 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:48,870 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.5 GiB) (status code: 500)
2026-01-10 14:14:49,382 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:49,383 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:49,735 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:49,736 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.5 GiB) (status code: 500)
2026-01-10 14:14:50,245 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:50,247 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:50,589 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:50,589 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.5 GiB) (status code: 500)
2026-01-10 14:14:51,103 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:51,105 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:51,465 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:51,465 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.5 GiB) (status code: 500)
2026-01-10 14:14:51,978 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:51,980 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:52,267 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:52,268 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.8 GiB) (status code: 500)
2026-01-10 14:14:52,775 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:52,776 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:53,114 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:53,115 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.8 GiB) (status code: 500)
2026-01-10 14:14:53,620 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:53,620 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:54,009 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:54,009 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:14:54,512 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:54,512 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:55,444 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:55,444 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:14:55,948 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:55,949 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:56,787 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:56,788 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:14:57,293 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:57,293 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:58,126 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:58,126 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:14:58,630 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:58,630 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:14:59,005 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:14:59,006 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:14:59,513 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:14:59,514 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:00,365 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:00,366 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:00,874 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:00,875 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:01,694 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:01,695 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:02,198 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:02,198 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:02,480 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:02,480 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:02,983 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:02,983 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:03,250 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:03,250 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:03,755 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:03,756 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:04,223 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:04,223 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:15:04,728 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:04,728 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:05,569 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:05,570 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:15:06,079 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:06,081 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:06,439 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:06,439 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:15:06,950 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:06,952 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:07,305 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:07,306 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:07,809 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:07,810 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:08,081 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:08,081 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:08,591 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:08,593 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:08,924 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:08,924 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:09,428 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:09,429 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:09,712 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:09,713 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:10,218 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:10,219 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:10,994 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:10,995 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:11,501 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:11,503 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:11,859 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:11,860 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:12,363 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:12,364 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:13,290 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:13,291 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:15:13,801 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:13,802 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:14,625 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:14,625 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:15:15,130 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:15,131 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:15,435 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:15,435 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:15,939 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:15,940 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:16,289 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:16,289 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:16,799 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:16,801 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:17,156 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:17,157 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:17,666 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:17,668 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:18,016 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:18,016 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:18,522 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:18,523 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:18,882 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:18,883 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:19,391 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:19,391 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:19,786 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:19,788 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:20,297 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:20,298 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:21,189 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:21,190 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:21,699 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:21,701 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:22,059 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:22,060 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:22,568 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:22,571 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:22,939 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:22,939 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:23,445 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:23,445 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:23,714 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:23,714 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:24,222 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:24,223 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:24,499 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:24,500 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:25,002 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:25,003 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:25,849 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:25,850 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:26,358 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:26,360 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:26,744 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:26,745 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:27,251 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:27,252 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:27,639 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:27,639 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:28,142 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:28,142 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:28,528 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:28,529 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:29,034 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:29,035 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:29,324 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:29,325 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:29,832 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:29,833 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:30,172 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:30,172 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:30,679 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:30,679 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:30,971 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:30,971 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:31,477 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:31,478 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:31,765 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:31,766 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.2 GiB) (status code: 500)
2026-01-10 14:15:32,278 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:32,280 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:32,640 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:32,640 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:33,147 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:33,148 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:33,498 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:33,499 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.2 GiB) (status code: 500)
2026-01-10 14:15:34,004 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:34,004 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:34,332 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:34,332 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:34,842 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:34,844 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:35,184 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:35,184 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.2 GiB) (status code: 500)
2026-01-10 14:15:35,690 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:35,690 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:35,983 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:35,983 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:36,486 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:36,486 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:36,848 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:36,848 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:37,351 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:37,353 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:37,734 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:37,734 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:38,239 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:38,239 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:38,606 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:38,606 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:39,111 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:39,111 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:39,529 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:39,529 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:15:40,033 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:40,034 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:40,418 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:40,419 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:15:40,923 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:40,923 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:41,783 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:41,783 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:15:42,292 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:42,294 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:43,221 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:43,221 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:15:43,734 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:43,736 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:44,575 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:44,576 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:15:45,086 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:45,086 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:45,436 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:45,436 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:15:45,946 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:45,947 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:46,327 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:46,328 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:15:46,831 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:46,832 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:47,212 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:47,213 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:47,718 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:47,718 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:48,571 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:48,572 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:15:49,081 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:49,082 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:49,974 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:49,975 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:15:50,479 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:50,479 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:50,777 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:50,777 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:51,282 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:51,283 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:51,623 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:51,624 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:52,131 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:52,132 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:52,433 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:52,433 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:52,939 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:52,940 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:53,937 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:53,938 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:15:54,441 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:54,442 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:55,340 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:55,341 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:55,845 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:55,846 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:56,213 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:56,213 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:56,722 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:56,722 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:57,057 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:57,058 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:57,562 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:57,562 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:57,856 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:57,857 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:58,365 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:58,365 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:58,735 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:58,735 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:15:59,239 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:15:59,240 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:15:59,607 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:15:59,607 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:00,111 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:00,111 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:00,459 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:00,459 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:00,964 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:00,965 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:01,283 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:01,284 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:01,789 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:01,789 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:02,081 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:02,082 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:02,585 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:02,585 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:02,861 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:02,861 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:03,368 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:03,369 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:03,717 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:03,717 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:04,222 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:04,223 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:04,575 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:04,575 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:05,078 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:05,079 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:05,380 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:05,380 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:05,883 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:05,884 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:06,728 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:06,729 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:07,232 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:07,232 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:08,110 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:08,110 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:16:08,616 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:08,618 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:09,517 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:09,517 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.9 GiB) (status code: 500)
2026-01-10 14:16:10,026 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:10,026 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:10,373 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:10,373 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:10,877 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:10,878 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:11,162 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:11,162 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:11,665 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:11,666 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:11,941 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:11,943 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:12,446 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:12,446 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:12,743 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:12,744 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:16:13,248 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:13,248 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:13,526 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:13,527 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:14,030 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:14,030 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:14,308 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:14,309 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:16:14,813 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:14,813 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:15,116 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:15,117 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:16:15,624 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:15,624 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:15,944 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:15,944 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:16,455 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:16,457 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:16,741 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:16,741 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:16:17,252 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:17,253 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:17,592 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:17,593 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:18,102 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:18,102 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:18,402 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:18,403 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:18,911 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:18,911 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:19,264 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:19,265 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:19,769 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:19,770 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:20,045 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:20,046 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:20,551 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:20,552 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:21,480 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:21,480 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.2 GiB) (status code: 500)
2026-01-10 14:16:21,985 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:21,985 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:22,898 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:22,900 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:23,403 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:23,404 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:23,817 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:23,818 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:24,321 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:24,321 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:24,608 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:24,608 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:25,112 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:25,113 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:25,992 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:25,993 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:26,496 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:26,497 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:27,491 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:27,492 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:27,998 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:27,998 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:28,406 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:28,406 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.1 GiB) (status code: 500)
2026-01-10 14:16:28,915 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:28,915 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:29,189 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:29,189 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.0 GiB) (status code: 500)
2026-01-10 14:16:29,692 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:29,692 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:29,980 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:29,980 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.2 GiB) (status code: 500)
2026-01-10 14:16:30,484 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:30,485 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:30,774 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:30,774 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.2 GiB) (status code: 500)
2026-01-10 14:16:31,279 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:31,279 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:31,552 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:31,552 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.2 GiB) (status code: 500)
2026-01-10 14:16:32,057 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:32,058 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:33,012 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:33,013 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.2 GiB) (status code: 500)
2026-01-10 14:16:33,521 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:33,522 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:34,341 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:34,341 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.2 GiB) (status code: 500)
2026-01-10 14:16:34,845 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:34,845 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:35,185 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:35,186 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.2 GiB) (status code: 500)
2026-01-10 14:16:35,690 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:35,690 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:35,968 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:35,969 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.2 GiB) (status code: 500)
2026-01-10 14:16:36,479 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:36,479 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:36,757 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:36,758 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.2 GiB) (status code: 500)
2026-01-10 14:16:37,269 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:37,271 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:38,095 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:38,095 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.3 GiB) (status code: 500)
2026-01-10 14:16:38,600 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:38,601 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:38,884 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:38,884 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.3 GiB) (status code: 500)
2026-01-10 14:16:39,387 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:39,388 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:39,667 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:39,668 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.3 GiB) (status code: 500)
2026-01-10 14:16:40,175 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:40,176 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:40,526 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:40,526 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.3 GiB) (status code: 500)
2026-01-10 14:16:41,031 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:41,032 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:41,389 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:41,389 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.3 GiB) (status code: 500)
2026-01-10 14:16:41,894 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:41,894 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:42,785 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:42,785 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.3 GiB) (status code: 500)
2026-01-10 14:16:43,289 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:43,289 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:44,138 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:44,138 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.3 GiB) (status code: 500)
2026-01-10 14:16:44,647 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:44,648 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:45,638 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:45,638 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:16:46,142 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:46,142 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:46,583 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:46,584 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:16:47,092 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:47,092 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:47,471 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:47,472 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:16:47,977 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:47,979 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:48,263 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:48,263 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:16:48,767 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:48,767 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:49,694 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:49,697 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:16:50,206 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:50,206 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:51,083 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:51,084 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:16:51,588 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:51,589 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:51,865 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:51,866 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:16:52,369 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:52,369 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:52,764 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:52,764 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:16:53,272 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:53,272 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:53,631 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:53,631 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:16:54,135 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:54,136 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:54,494 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:54,494 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:16:54,997 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:54,997 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:55,358 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:55,358 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:16:55,867 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:55,868 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:56,187 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:56,187 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:16:56,695 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:56,695 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:57,558 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:57,559 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:16:58,062 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:58,062 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:58,891 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:58,891 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:16:59,395 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:16:59,395 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:16:59,802 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:16:59,803 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:00,307 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:00,307 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:01,127 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:01,127 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:17:01,632 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:01,632 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:02,000 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:02,001 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:17:02,505 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:02,506 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:03,365 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:03,365 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:17:03,869 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:03,869 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:04,756 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:04,756 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:17:05,259 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:05,260 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:06,127 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:06,128 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:17:06,633 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:06,633 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:06,918 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:06,919 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:17:07,426 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:07,427 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:07,810 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:07,810 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:17:08,313 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:08,314 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:08,611 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:08,611 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:17:09,122 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:09,123 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:09,408 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:09,408 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:17:09,916 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:09,918 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:10,271 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:10,272 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:10,774 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:10,775 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:11,111 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:11,111 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:11,625 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:11,626 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:11,901 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:11,901 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:12,405 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:12,405 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:12,694 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:12,694 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:13,198 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:13,198 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:13,584 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:13,585 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:17:14,088 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:14,088 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:14,495 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:14,496 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:17:14,999 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:14,999 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:15,326 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:15,327 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:17:15,830 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:15,830 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:16,133 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:16,134 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:17:16,638 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:16,638 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:17,488 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:17,489 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:17:17,992 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:17,993 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:18,855 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:18,856 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:17:19,360 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:19,361 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:19,646 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:19,646 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:17:20,155 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:20,159 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:21,017 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:21,017 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:21,525 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:21,525 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:21,804 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:21,805 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.4 GiB) (status code: 500)
2026-01-10 14:17:22,313 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:22,314 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:22,576 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:22,576 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:23,081 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:23,081 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:23,357 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:23,357 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:23,866 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:23,868 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:24,171 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:24,172 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:24,682 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:24,683 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:25,029 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:25,030 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:25,539 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:25,539 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:25,819 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:25,820 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:26,325 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:26,326 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:26,690 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:26,691 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:27,195 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:27,196 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:27,476 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:27,477 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:27,987 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:27,987 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:28,272 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:28,272 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:28,780 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:28,781 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:29,093 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:29,094 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:29,602 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:29,602 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:29,872 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:29,872 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:30,381 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:30,382 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:30,676 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:30,676 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:31,187 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:31,188 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:31,458 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:31,459 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:31,968 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:31,970 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:32,322 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:32,322 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:32,832 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:32,834 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:33,172 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:33,172 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:33,680 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:33,680 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:33,990 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:33,990 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:34,498 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:34,498 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:34,853 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:34,854 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:35,356 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:35,356 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:35,779 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:35,780 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:36,284 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:36,284 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:36,683 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:36,683 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:37,188 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:37,189 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:38,006 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:38,006 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:38,519 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:38,519 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:38,871 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:38,872 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:39,383 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:39,385 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:39,724 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:39,724 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:40,232 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:40,232 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:41,150 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:41,150 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:41,659 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:41,660 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:42,477 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:42,477 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:42,984 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:42,985 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:43,947 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:43,947 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:44,451 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:44,452 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:45,267 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:45,267 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:45,771 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:45,772 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:46,104 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:46,105 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:46,608 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:46,608 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:46,983 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:46,984 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:47,489 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:47,489 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:47,925 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:47,927 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:48,430 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:48,430 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:48,767 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:48,767 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:49,270 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:49,271 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:49,641 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:49,642 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:50,150 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:50,150 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:51,106 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:51,107 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:51,611 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:51,611 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:52,489 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:52,489 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:52,993 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:52,993 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:53,865 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:53,866 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:54,371 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:54,372 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:55,188 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:55,189 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.6 GiB) (status code: 500)
2026-01-10 14:17:55,698 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:55,698 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:55,998 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:56,000 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:56,509 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:56,510 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:56,783 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:56,784 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:57,293 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:57,295 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:57,580 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:57,580 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:58,087 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:58,088 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:58,379 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:58,380 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:58,882 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:58,882 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2026-01-10 14:17:59,160 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2026-01-10 14:17:59,161 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (2.5 GiB) (status code: 500)
2026-01-10 14:17:59,675 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2026-01-10 14:17:59,678 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
