2025-12-25 12:38:11,425 - INFO - [__main__] - AI Model Evaluation Starting...
2025-12-25 12:38:11,425 - INFO - [__main__] - STARTING: Configuration Initialization
2025-12-25 12:38:11,437 - INFO - [__main__] - Initializing system components...
2025-12-25 12:38:11,448 - INFO - [model_layer.model_integration] - ✅ Ollama client initialized
2025-12-25 12:38:11,471 - INFO - [evaluation_layer.sandbox_executor] - Docker client initialized
2025-12-25 12:38:11,471 - INFO - [__main__] - All components initialized successfully
2025-12-25 12:38:11,471 - INFO - [__main__] - COMPLETED: Configuration Initialization in 0.05s
2025-12-25 12:38:11,471 - INFO - [__main__] - Starting evaluation with test configuration...
2025-12-25 12:38:11,472 - INFO - [__main__] - Starting AI Model Evaluation Pipeline with Enhanced Debugging
2025-12-25 12:38:11,472 - INFO - [__main__] - ============================================================
2025-12-25 12:38:11,472 - INFO - [__main__] - Configuration: 1 models, 2 samples per task
2025-12-25 12:38:11,472 - INFO - [__main__] - STARTING: Dataset Loading
2025-12-25 12:38:11,472 - INFO - [__main__] - Loading HumanEval dataset...
2025-12-25 12:38:11,521 - INFO - [__main__] - Loaded 164 problems
2025-12-25 12:38:11,521 - INFO - [__main__] - COMPLETED: Dataset Loading in 0.05s
2025-12-25 12:38:11,521 - INFO - [__main__] - STARTING: Model Detection and Validation
2025-12-25 12:38:11,522 - INFO - [__main__] - Checking model availability...
2025-12-25 12:38:13,762 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2025-12-25 12:38:13,767 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2025-12-25 12:38:13,767 - INFO - [__main__] - Available models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2025-12-25 12:38:13,767 - INFO - [__main__] - Final model selection: ['codellama:7b']
2025-12-25 12:38:13,767 - INFO - [__main__] - COMPLETED: Model Detection and Validation in 2.25s
2025-12-25 12:38:13,767 - INFO - [__main__] - STARTING: Code Generation
2025-12-25 12:38:13,767 - INFO - [__main__] - Generating code solutions...
2025-12-25 12:38:13,772 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2025-12-25 12:38:13,773 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2025-12-25 12:38:16,988 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2025-12-25 12:38:16,989 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.3 GiB) (status code: 500)
2025-12-25 12:38:17,499 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2025-12-25 12:38:17,500 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2025-12-25 12:38:18,617 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2025-12-25 12:38:18,617 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1.0 GiB) (status code: 500)
2025-12-25 12:38:19,130 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2025-12-25 12:38:19,130 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2025-12-25 12:38:19,606 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2025-12-25 12:38:19,606 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1012.6 MiB) (status code: 500)
2025-12-25 12:38:20,111 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2025-12-25 12:38:20,111 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2025-12-25 12:38:20,474 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2025-12-25 12:38:20,474 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1015.4 MiB) (status code: 500)
2025-12-25 12:38:20,978 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2025-12-25 12:38:20,978 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2025-12-25 12:38:21,846 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2025-12-25 12:38:21,847 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (1001.8 MiB) (status code: 500)
2025-12-25 12:38:22,350 - INFO - [httpx] - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2025-12-25 12:38:22,351 - INFO - [model_layer.model_integration] - Found Ollama models: ['codellama:7b', 'deepseek-r1:1.5b', 'tinyllama:latest', 'qwen:1.8b', 'deepseek-r1:latest']
2025-12-25 12:38:22,691 - INFO - [httpx] - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 500 Internal Server Error"
2025-12-25 12:38:22,691 - ERROR - [model_layer.model_integration] - ❌ Ollama generation failed: model requires more system memory (3.0 GiB) than is available (989.2 MiB) (status code: 500)
2025-12-25 12:38:23,206 - INFO - [__main__] - Generation results: 6 successful, 0 failed
2025-12-25 12:38:23,206 - INFO - [__main__] - COMPLETED: Code Generation in 9.44s
2025-12-25 12:38:23,216 - INFO - [__main__] - Saved solutions CSV to: results\generated_solutions.csv
2025-12-25 12:38:23,217 - INFO - [__main__] - STARTING: Saving Individual Solution Files
2025-12-25 12:38:23,217 - INFO - [__main__] - Creating directory structure in: results\individual_solutions
2025-12-25 12:38:23,225 - INFO - [__main__] - Saved 12 individual files (0 errors)
2025-12-25 12:38:23,225 - INFO - [__main__] - COMPLETED: Saving Individual Solution Files in 0.01s
2025-12-25 12:38:23,225 - INFO - [__main__] - Individual solutions saved to: results\individual_solutions
2025-12-25 12:38:23,226 - INFO - [__main__] - STARTING: Test Execution from Individual Files
2025-12-25 12:38:23,226 - INFO - [__main__] - Executing tests from individual solution files...
2025-12-25 12:38:23,253 - INFO - [evaluation_layer.sandbox_executor] - Docker client available: True
2025-12-25 12:38:23,253 - INFO - [evaluation_layer.sandbox_executor] - Choosing Docker execution path
2025-12-25 12:38:23,255 - WARNING - [evaluation_layer.sandbox_executor] - Could not extract function name, using 'candidate'
2025-12-25 12:38:23,256 - INFO - [evaluation_layer.sandbox_executor] - Using function name 'candidate' for test execution
2025-12-25 12:38:23,261 - INFO - [evaluation_layer.sandbox_executor] - Starting Docker container execution for HumanEval/0
2025-12-25 12:38:26,338 - ERROR - [evaluation_layer.sandbox_executor] - Docker container error: Command '['python', '/tmp/test.py']' in image 'python:3.9-slim' returned non-zero exit status 2: b''
2025-12-25 12:38:26,341 - INFO - [evaluation_layer.sandbox_executor] - Docker client available: True
2025-12-25 12:38:26,341 - INFO - [evaluation_layer.sandbox_executor] - Choosing Docker execution path
2025-12-25 12:38:26,342 - WARNING - [evaluation_layer.sandbox_executor] - Could not extract function name, using 'candidate'
2025-12-25 12:38:26,342 - INFO - [evaluation_layer.sandbox_executor] - Using function name 'candidate' for test execution
2025-12-25 12:38:26,343 - INFO - [evaluation_layer.sandbox_executor] - Starting Docker container execution for HumanEval/0
2025-12-25 12:38:27,374 - ERROR - [evaluation_layer.sandbox_executor] - Docker container error: Command '['python', '/tmp/test.py']' in image 'python:3.9-slim' returned non-zero exit status 2: b''
2025-12-25 12:38:27,377 - INFO - [evaluation_layer.sandbox_executor] - Docker client available: True
2025-12-25 12:38:27,377 - INFO - [evaluation_layer.sandbox_executor] - Choosing Docker execution path
2025-12-25 12:38:27,377 - WARNING - [evaluation_layer.sandbox_executor] - Could not extract function name, using 'candidate'
2025-12-25 12:38:27,378 - INFO - [evaluation_layer.sandbox_executor] - Using function name 'candidate' for test execution
2025-12-25 12:38:27,379 - INFO - [evaluation_layer.sandbox_executor] - Starting Docker container execution for HumanEval/1
2025-12-25 12:38:28,292 - ERROR - [evaluation_layer.sandbox_executor] - Docker container error: Command '['python', '/tmp/test.py']' in image 'python:3.9-slim' returned non-zero exit status 2: b''
2025-12-25 12:38:28,294 - INFO - [evaluation_layer.sandbox_executor] - Docker client available: True
2025-12-25 12:38:28,294 - INFO - [evaluation_layer.sandbox_executor] - Choosing Docker execution path
2025-12-25 12:38:28,295 - WARNING - [evaluation_layer.sandbox_executor] - Could not extract function name, using 'candidate'
2025-12-25 12:38:28,295 - INFO - [evaluation_layer.sandbox_executor] - Using function name 'candidate' for test execution
2025-12-25 12:38:28,296 - INFO - [evaluation_layer.sandbox_executor] - Starting Docker container execution for HumanEval/1
2025-12-25 12:38:29,134 - ERROR - [evaluation_layer.sandbox_executor] - Docker container error: Command '['python', '/tmp/test.py']' in image 'python:3.9-slim' returned non-zero exit status 2: b''
2025-12-25 12:38:29,136 - INFO - [evaluation_layer.sandbox_executor] - Docker client available: True
2025-12-25 12:38:29,137 - INFO - [evaluation_layer.sandbox_executor] - Choosing Docker execution path
2025-12-25 12:38:29,138 - WARNING - [evaluation_layer.sandbox_executor] - Could not extract function name, using 'candidate'
2025-12-25 12:38:29,139 - INFO - [evaluation_layer.sandbox_executor] - Using function name 'candidate' for test execution
2025-12-25 12:38:29,141 - INFO - [evaluation_layer.sandbox_executor] - Starting Docker container execution for HumanEval/2
2025-12-25 12:38:30,002 - ERROR - [evaluation_layer.sandbox_executor] - Docker container error: Command '['python', '/tmp/test.py']' in image 'python:3.9-slim' returned non-zero exit status 2: b''
2025-12-25 12:38:30,005 - INFO - [evaluation_layer.sandbox_executor] - Docker client available: True
2025-12-25 12:38:30,005 - INFO - [evaluation_layer.sandbox_executor] - Choosing Docker execution path
2025-12-25 12:38:30,006 - WARNING - [evaluation_layer.sandbox_executor] - Could not extract function name, using 'candidate'
2025-12-25 12:38:30,006 - INFO - [evaluation_layer.sandbox_executor] - Using function name 'candidate' for test execution
2025-12-25 12:38:30,007 - INFO - [evaluation_layer.sandbox_executor] - Starting Docker container execution for HumanEval/2
2025-12-25 12:38:30,860 - ERROR - [evaluation_layer.sandbox_executor] - Docker container error: Command '['python', '/tmp/test.py']' in image 'python:3.9-slim' returned non-zero exit status 2: b''
2025-12-25 12:38:30,861 - INFO - [__main__] - Execution sources: {'docker_error': 6}
2025-12-25 12:38:30,862 - INFO - [__main__] - COMPLETED: Test Execution from Individual Files in 7.64s
2025-12-25 12:38:30,862 - INFO - [__main__] - STARTING: Results Combination
2025-12-25 12:38:30,885 - INFO - [__main__] - Combined 6 results
2025-12-25 12:38:30,886 - INFO - [__main__] - COMPLETED: Results Combination in 0.02s
2025-12-25 12:38:30,886 - INFO - [__main__] - STARTING: Metrics Calculation
2025-12-25 12:38:30,886 - INFO - [__main__] - Calculating evaluation metrics...
2025-12-25 12:38:30,907 - INFO - [__main__] - Metrics calculated successfully
2025-12-25 12:38:30,909 - INFO - [__main__] - COMPLETED: Metrics Calculation in 0.02s
2025-12-25 12:38:30,909 - INFO - [__main__] - STARTING: Results Persistence
2025-12-25 12:38:30,919 - INFO - [__main__] - Results saved to:
2025-12-25 12:38:30,920 - INFO - [__main__] -    Solutions: results\generated_solutions.csv
2025-12-25 12:38:30,920 - INFO - [__main__] -    Individual Files: results\individual_solutions
2025-12-25 12:38:30,921 - INFO - [__main__] -    Full Results: results\evaluation_results.csv
2025-12-25 12:38:30,921 - INFO - [__main__] -    Comparison: results\model_comparison.csv
2025-12-25 12:38:30,921 - INFO - [__main__] - COMPLETED: Results Persistence in 0.01s
2025-12-25 12:38:30,922 - INFO - [__main__] - EVALUATION COMPLETE!
2025-12-25 12:38:30,922 - INFO - [__main__] - ============================================================
2025-12-25 12:38:30,924 - INFO - [__main__] - OVERALL STATISTICS:
2025-12-25 12:38:30,925 - INFO - [__main__] -    Total Solutions: 6
2025-12-25 12:38:30,926 - INFO - [__main__] -    Passed Solutions: 0
2025-12-25 12:38:30,927 - INFO - [__main__] -    Overall Pass Rate: 0.0%
2025-12-25 12:38:30,929 - INFO - [__main__] - FUNCTIONAL CORRECTNESS METRICS:
2025-12-25 12:38:30,931 - INFO - [__main__] -    pass@1: 0.000
2025-12-25 12:38:30,931 - INFO - [__main__] -    pass@5: 0.000
2025-12-25 12:38:30,932 - INFO - [__main__] -    pass@10: 0.000
2025-12-25 12:38:30,932 - INFO - [__main__] - 
MODEL COMPARISON:
2025-12-25 12:38:30,932 - INFO - [__main__] -    codellama:7b:
2025-12-25 12:38:30,933 - INFO - [__main__] -      Pass Rate: 0.000
2025-12-25 12:38:30,933 - INFO - [__main__] -      Pass@1: 0.000
2025-12-25 12:38:30,933 - INFO - [__main__] -      Pass@5: 0.000
2025-12-25 12:38:30,933 - INFO - [__main__] -      Total Tests: 6
2025-12-25 12:38:30,934 - INFO - [__main__] - 
Evaluation completed successfully!
2025-12-25 12:38:30,934 - INFO - [__main__] - Start the dashboard with: python dashboard/app.py
